---
title: Anatomy of a Graph Mind
date: 2022-06-03 20:06:14.000000000 Z
layout: post-external
original_link: https://studio.ribbonfarm.com/p/anatomy-of-a-graph-mind
author: 100041
---

_This is part of the [Graph Minds Notebook](https://studio.ribbonfarm.com/p/graph-minds-notebook?s=w) series_

One of the first things I like to do when exploring a big topic is test whether any unexamined conceptual metaphors I’m bringing to the topic are sound. In the case of graph minds, which are a particular conceptualization of collective intelligence, there are two such conceptual metaphors: The metaphor of a graph, as in the mathematical concept of a set of nodes linked by edges, and the metaphor of a brain. These are not the only metaphors available. You could conceptualize collective intelligences as weather systems, fluid flows, or steampunk assemblages of machinery for example. But in this series, we’re going with graphs and brains.

I don’t yet have a good handle on the graph metaphor, but the brain metaphor (setting aside the mind/brain problem for the moment) seems like an easier one to think through. Note that the brain is a special kind of graph (a neural network of billions of neurons), so we’ll get some indirect insight into the graph metaphor too. But it’s important to keep in mind that a brain is not _just_ a kind of graph or network.

What do we put on the other side of the mapping? I always find it best to work out a particular instance of a conceptual metaphor mapping before speculating on generalities, so we have a lot of choices. We could map a brain to a city, to a corporation, to a civilization, and so on. But I think the most useful mapping is to the kind we are all experimenting with on a large scale in 2022 — graph minds constructed out of social media technologies. Not only are such minds arguably the most complex ever in history, they allow for two species to form a symbiotic graph mind — humans and silicon-based AIs.

In particular, I’m thinking of bounded, semi-private graph minds that might be built around a discord for example (in the “True Borgs” upper right quadrant in [the 2x2 from last time](https://studio.ribbonfarm.com/p/surrender-and-assimilation?s=w)).

So without further ado, here is my visual map of the metaphor, using a standard anatomical drawing of a brain, with its major lobes, as the foundation.

[![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414916b1-6143-4263-87a4-f955aa521e94_2732x2048.png)](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414916b1-6143-4263-87a4-f955aa521e94_2732x2048.png)

The level of the mapping is at the level of major lobes, and [Wikipedia glosses of their core functions](https://en.wikipedia.org/wiki/Lobes_of_the_brain). There’s all sorts of nuances lost here of course. Brain regions have plasticity and can shift their functional role over time. Functions aren’t precisely located in regions, and many regions may participate in a function. Nor are functions precisely defined. Even the side view I’m using here elides some important features, such as lateral asymmetry effects (left/right brain stuff).

Still, there’s some first-order utility to the mapping here. At a _very_ rough level, we have:

1. The **frontal lobe** handles executive attention and basic, live processing of decisions and open-loop actions. Clearly, that maps to what happens in the main activity streams of a graph mind, such as the channels of a Discord server.

2. The **parietal lobe** seems to be mainly about what I think of as “sensor fusion” — integrating the five senses, plus proprioception, to form a gestalt “sense of the body” in a situated way. This, I think, clearly maps to the most embodied regimes of graph mind behaviors — meetups, zoom calls, audio calls. Activities where we form the most intimate and holistic sense of each other both as individuals and collectives, _in_ a larger situation or context.

3. The **occipital lobe** is specialized visual processing. Humans are a very visual species. Fortunately, so are human+computer based graph minds. We do a lot of our collective sense-making through visual modes. Computers didn’t get to be that way until recently, but since the iPhone, computers are primarily visual input devices too. So I think collective map making by/of/for a graph mind maps here. This includes both literal visuals (such as map-like graphics), and spatial mental models of collective selves.

4. The **temporal lobe** is, roughly, speaking, language and long-term memory. So that maps to shared archival media, such as collaborative notebooks or forums. In terms of content, I think this is where lore and lexicon live. Unlike the streams flowing through the frontal-lobe media, the temporal lobe media persist strongly, and provide an evolving context.

5. The **limbic system** is emotional processing, and I think this maps to memes, which is how social media graph minds express and process emotions internally. The boundary with lore/lexicon starts to blur a bit, but so does the anatomy, so that’s fine.

6. And finally, the lower brain structures — **cerebellum** , **brain stem** , and top of **spinal cord** — are all much more strongly automated and closed-loop, so I have mapped governance (cerebellum), rituals and rules (brain stem), and automation/bots (spinal cord) to these parts.

An interesting feature of this mapping is that it is naturally functional and behavioral, and only implicitly structural. We’re not mapping individuals to parts of the brain, or groups to larger regions. We’re mapping graph mind behaviors and functions to brain behaviors and functions.

I don’t think this is an accident. It’s actually quite hard to map individual humans or AIs to parts of the brain structurally.

For example, the intuitive mapping of individual neurons to individual humans doesn’t really work. Neurons are too simple. They have a bunch of inputs, and an output, and a simple logic governing when they fire. The connections are also relatively static, though they do change over time.

And individuals don’t stay functionally or behaviorally static within a graph mind. You might post a meme today, and vote in a governance event tomorrow.

In fact, I think the right mapping for individuals is as a locus of behavioral focal points. I have illustrated this with the red loops. If in my graph mind, I mainly hang out in the main discord channels, and occasionally head over to Roam to edit or “garden” some shared notes, I am represented by a loop that traverses the frontal lobe and temporal lobe.

This is initially annoying — wouldn’t it be nice to have a neat structural mapping?

But if you stop to consider the implications, this is actually a much richer way to conceptualize individuals. Individuals are “brain waves” — moving patterns of activity on the basic functional map. Waves that can create temporal rhythms, reflect and refract, strengthen or attenuate, and interfere with each other constructively or destructively. This is rather neat, if you ask me. And it doesn’t actually preclude structurally localized participation. Maybe one person just hangs out in the cerebellum doing nothing but maintaining the governance infrastructure and riding herd getting people to vote and stuff.

Humans-as-brainwaves also allows us to “count” the number of active humans in a reasonable way: it is the number of informationally correlated and distinct waves active in the brain in a given epoch (instantaneous I think is too reductive). So you might pick a weekday say, and based on the calendar of events and more ad-hoc events, work out the activity waves. From a social media perspective, this maps to daily-active-users type metrics. From a brain perspective, it maps to coherent patterns in fMRI scans that are reproducible by reproducing conditions. Pass-through visitors to the Discord, or random anomalous waves on the fMRI, aren’t really part of the graph mind/brain.

Can we extend this kind of mapping to other examples? I actually doubt it. Things like cities, corporations, and nations are not primarily brain-like things. They are whole-body-like things. They’d map better to the whole human body (the transportation system would be feet for example, and the energy system would be the metabolic system). Social media graph minds are unique in that they are highly disembodied and don’t do many non-brain-like things. They see, they think, they talk.

In future, this might change. Once robots are part of the equation and we have skynet like things, graph minds can become much more highly embodied, and access much stronger actuation modes than merely publishing and broadcasting information. That would be graph minds in IoT (internet of things) bodies.

In future, this kind of digitally mediated graph mind can only grow stronger. Throw metaverse tech and blockchain tech into the mix, and very interesting richness becomes possible. Throw in brain-to-brain and brain-to-machine interfaces, and we’re really cooking. We might even get emergent subjective consciousness and collective qualia.

Of course, it is important to note that this metaphor, like any metaphor, also de-emphasizes some elements on either end, and even blinds you to phenomenology that doesn’t quite fit.

I can’t actually think of anything major that doesn’t fit this metaphor from either direction though — every aspect of social media graph minds seems to map properly to some aspect of the brain (or soon will, with technologies already on their way), and vice versa.

But I’m almost certainly missing something. Can you spot anything?

What aspects of graph mind phenomenology does the brain metaphor _not_ cover?

