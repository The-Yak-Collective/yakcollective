---
title: Cynefin with Examples
date: 2021-09-07 04:53:11.000000000 Z
layout: post-external
original_link: https://hiredthought.com/2021/09/07/cynefin-with-examples/
author: 100080
---

[Cynefin](https://en.wikipedia.org/wiki/Cynefin_framework) is a public domain _(citation needed)_, complexity-centered framework for sense-making. There are 5 ontological domains (you can call them quadrants if you want to piss off certain corners of the internet) — **Clear** (formerly Simple/Obvious), **Complicated** , **Complex** , **Chaotic** , and **Disorder**. Each domain suggests its own specific way of being.

I’m going to describe this framework in terms I find useful, practically.

At any point in time, you are in one of three possible circumstances described below. If you don’t know which one you’re in, then you’re in **Disorder**.

## 1. **Cause and Effect is Predictable and Knowable**

With a problem in this space, the situation may be completely **Clear (formerly Simple/Obvious)**. Let’s say you’re building a new office space for your company. It is probably obvious that you should heat and cool the space (climate control). It is also probably obvious that you should put doors on the offices, have running water in the bathrooms, and have wireless internet for employee use. All these things are  **best practices**. You just do them, with entirely predictable outcomes.

The situations can also be a little harder. It might be a  **Complicated ** process to actually install an HVAC system, so you would likely hire an expert contractor to do it for you. It is also probably complicated figuring out how to design conference rooms to minimize acoustic problems. You could certainly learn about acoustic design considerations, analyze the designs, and attempt to do it yourself, but you might instead just bring in an expert to deal with it (for an expert in acoustic design, very little about sound is unknown). With each problem, there are always multiple  **good practices**  to choose from; one expert might do things differently than another, but both would achieve the goals in the end. Fundamentally, the outcomes are still predictable.

## 2. **Cause and Effect is Knowable Only in Retrospect**

An example here might be deciding how and whether to incorporate feedback/suggestions from your employees into the office design. Should you do what every single person says? Should you pick and choose only the ideas that sound good to you? Can you bring in an office design firm or hire a consultant to figure out what to do based on the feedback? You could do _any_ or _none_ of these options and not know how the employees will respond.

Let’s get more specific. Suppose that some employees have suggested adopting an open plan office space instead of cubicles, while other employees have registered strong opposition to the idea. What will happen if you choose either option? Or if you compromise by splitting the space 50% each way? Will everyone be satisfied? Will they be satisfied a year from now? What’s at risk if you get it wrong? The point is that so many different things _could _happen, and so much of the  **Complex**  system is _out of your control_. You just can’t know!  
There is no good or best practice, as outcomes just  **emerge**. You can look backwards to understand and explain why something _happened_, but you can’t necessarily use that knowledge to predict what _will happen_ the next time around.

The key to navigating this kind of situation is “safe-to-fail” experimentation. First, you identify ideas you have for getting “more” or “less” of something (e.g., one idea might be to split the space 50% open plan and 50% cubicles in order to bring about MORE stories of satisfaction with the office design). Then, identify all the things that can go wrong if you do that (e.g., a 50/50 split might not address the true proportion among employee preferences // the noise in the open plan space might affect the cubicle space // isolation might increase between these two kinds of employees). For each of those problems, identify strategies in advance that could mitigate them should they happen (e.g., use a non-permanent cubicle and open space design and continually adjust according to the supply/demand for each type of space // keep reserve funds for mobile sound-blocking partitions just in case they’re needed // shift around the break room or change the hallway pathing so accidental interaction between the groups is more probable). You also want to do the same thing for signs of success (but for amplifying the effects instead of mitigating them). While it might seem tedious, this process does improve outcomes in complexity.

## **3. No Cause and Effect**

If encountered accidentally, these are situations of crisis. If the building is on fire, for example, everyone will move as quickly as they can to the nearest exit to escape the situation. If encountered deliberately, however, **Chaos** can bring novelty. For example, arbitrarily removing all furniture in one section of the office will displace its occupants (and probably piss them off… so don’t do this), but how they cope with that little bit of chaos might bring about novel solutions to the open office vs cubicle dynamic.

* * *

The above is meant to be useful rather than correct. If you want a better post, please go write one. ![❤](https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/2764.png)

